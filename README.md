# Random Forest Demo

This project demonstrates the difference between a **Decision Tree Regressor** and a **Random Forest Regressor** by applying both models on the same dataset and comparing their performance.

The goal is to understand how ensemble learning (Random Forest) improves results over a single decision tree.

---

## Concepts Covered
- Decision Tree Regressor
- Random Forest Regressor
- Ensemble Learning
- Biasâ€“Variance Tradeoff
- Model performance comparison

---

## Workflow
1. Load and preprocess the dataset
2. Train a Decision Tree Regressor
3. Train a Random Forest Regressor
4. Compare predictions and performance metrics
5. Analyze why Random Forest performs better

---

## Algorithms Used
- Decision Tree Regressor
- Random Forest Regressor

---

## Libraries Used
- Python
- NumPy
- Pandas
- Scikit-learn
- Matplotlib / Seaborn (for visualization, if used)

---

## Key Learning
- Decision Trees tend to overfit the data
- Random Forest reduces overfitting by averaging multiple trees
- Ensemble models are generally more stable and accurate

---

## Use Case
This project is meant for learning and demonstration purposes to clearly understand how Random Forest improves upon Decision Trees in regression problems.
